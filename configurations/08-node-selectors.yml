
#
# Imagine a cluster with 3 nodes (n1, n2, n3) and 3 pods (p1, p2, p3) where:
#
#   - n1 & n2 are low cpu, low mem nodes
#   - n3 is a high cpu, high mem node
#
#   - p1 is a pod that does crazy BigData processing
#   - p1 & p2 are stupid pods and don't need much resources
#
# Lets say we now schedule all 3 pods.
# It is possible that we need with the following:
#   - p1 on n1
#   - p2 on n2
#   - p3 on n3
#
# This is bad because we were hoping p1 lands on n3.
# To achieve this, we can use Node Selectors.
#
# Two steps:
# 1. Apply label to a node
# 2. Apply the right selectors in the pod definition file
#

#
# kubectl label node <node-name> <label-key>=<label-value>
#
# kubectl label node n1 size=small
# kubectl label node n2 size=small
# kubectl label node n3 size=large
#
# Pods (p1):
#     apiVersion: v1
#     kind: Pod
#     metadata:
#       name: p1
#     spec:
#       containers:
#         - name: my-bigdata-processor-container
#           image: my-bigdata-processor
#       nodeSelector:
#         size: large
#
# Pods (p2, p3):
#     apiVersion: v1
#     kind: Pod
#     metadata:
#       name: p2/p3
#     spec:
#       containers:
#         - name: nginx-container
#           image: nginx
#       nodeSelector:
#         size: small
#
# Now when the above pods are scheduled, we'll have the right placement:
#   - p1 on n3
#   - p2 on n1
#   - p3 on n2
#

#
# Node selectors CANNOT solve all problems of custom placements.
# For eg: 
#   - how do we specify a selector that says place this pod on anything but "small" node.
#   - how do we specify a selector that says place this pod on either "medium" or "small" node.
#
# To answer these questions, we need Node Affinity.
#